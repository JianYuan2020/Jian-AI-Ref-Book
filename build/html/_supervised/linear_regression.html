
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Linear Regression &#8212; Jian AI Ref 0.1 documentation</title>
    <link rel="stylesheet" href="../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Logistic Regression" href="logistic_regression.html" />
    <link rel="prev" title="Supervised learning" href="../supervised_learning.html" /> 
  </head><body>
    <div class="header-wrapper" role="banner">
      <div class="header">
        <div class="headertitle"><a
          href="../index.html">Jian AI Ref 0.1 documentation</a></div>
        <div class="rel" role="navigation" aria-label="related navigation">
          <a href="../supervised_learning.html" title="Supervised learning"
             accesskey="P">previous</a> |
          <a href="logistic_regression.html" title="Logistic Regression"
             accesskey="N">next</a> |
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="linear-regression">
<span id="linear-regression-label"></span><h1>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>Linear regression with multiple variables/features</p>
</div></blockquote>
<dl class="simple">
<dt>Let’s define:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> = number of features</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> = number of training examples</p></li>
<li><p><span class="math notranslate nohighlight">\(x^{(i)}\)</span> = input (features) of <span class="math notranslate nohighlight">\(i^{th}\)</span> training example</p></li>
<li><p><span class="math notranslate nohighlight">\(x^{(i)}_{j}\)</span> = value of feature <span class="math notranslate nohighlight">\(j\)</span> in <span class="math notranslate nohighlight">\(i^{th}\)</span> training example</p></li>
<li><p><span class="math notranslate nohighlight">\(x^{(i)} = [ x^{(i)}_{1}; x^{(i)}_{2}; ...; x^{(i)}_{j}; ...; x^{(i)}_{n} ] \in \mathbb {R^{n}}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(X = [ (x^{(1)})^{T}; (x^{(2)})^{T}; ...; (x^{(i)})^{T}; ...; (x^{(m)})^{T} ] \in \mathbb {R^{m * n}}\)</span></p></li>
</ul>
</dd>
</dl>
<div class="section" id="hypothesis">
<h2>Hypothesis<a class="headerlink" href="#hypothesis" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(h_\theta (x) = \theta_{0} + \theta_{1} x_{1} + \theta_{2} x_{2} + ... + \theta_{j} x_{j} + ... + \theta_{n} x_{n}\)</span></p>
<p>Let: <span class="math notranslate nohighlight">\(x_{0} = 1\)</span> (<span class="math notranslate nohighlight">\(x^{(i)}_{0} = 1\)</span> for every <span class="math notranslate nohighlight">\(i = 1, ..., m\)</span>):</p>
<p><span class="math notranslate nohighlight">\(x = [ x_{0}; x_{1}; x_{2}; ...; x_{j}; ...; x_{n} ] \in \mathbb {R^{n + 1}}\)</span></p>
</div></blockquote>
</div>
<div class="section" id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\Theta = [ \theta_{0}; \theta_{1}; \theta_{2}; ...; \theta_{j}; ...; \theta_{n} ] \in \mathbb {R^{n + 1}}\)</span></p>
<p>Therefore:</p>
<p><span class="math notranslate nohighlight">\(h_\theta (x) = \theta_{0} x_{0} + \theta_{1} x_{1} + \theta_{2} x_{2} + ... + \theta_{j} x_{j} + ... + \theta_{n} x_{n}\)</span></p>
<p><span class="math notranslate nohighlight">\(h_\theta (x) = \Theta^{T} x \in \mathbb {R}\)</span></p>
</div></blockquote>
</div>
<div class="section" id="octave-code">
<h2>Octave Code<a class="headerlink" href="#octave-code" title="Permalink to this headline">¶</a></h2>
<div class="highlight-octave notranslate"><div class="highlight"><pre><span></span><span class="n">h_theta_x</span> <span class="p">=</span> <span class="n">theta</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">x</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="section" id="cost-function">
<h2>Cost Function<a class="headerlink" href="#cost-function" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(J(\Theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)})^2\)</span></p>
</div></blockquote>
</div>
<div class="section" id="gradient-descent">
<h2>Gradient Descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Also called Batch Gradient Descent for it’s processing all training examples in one batch at every iteration</p>
<p><span class="math notranslate nohighlight">\(\theta_{j} = \theta_{j} - \alpha \frac{\partial }{\partial \theta_{j}} J(\Theta)\)</span></p>
<p>Repeat for each iteration {</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\theta_{j} = \theta_{j} - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) x^{(i)}_{j}\)</span>; (<span class="math notranslate nohighlight">\(x_{0}^{(i)} = 1\)</span>, <span class="math notranslate nohighlight">\(j = 0, ..., n\)</span>)</p>
</div></blockquote>
<p>}</p>
<p><span class="math notranslate nohighlight">\(\alpha\)</span> = <a class="reference internal" href="../_appendix/learning_rate.html#learning-rate-label"><span class="std std-ref">Learning Rate</span></a></p>
</div></blockquote>
</div>
<div class="section" id="regularized-linear-regression">
<h2>Regularized Linear Regression<a class="headerlink" href="#regularized-linear-regression" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Adding <a class="reference internal" href="../_appendix/regularization.html#regularization-label"><span class="std std-ref">Regularization</span></a> to avoid overfitting:</p>
</div></blockquote>
<div class="section" id="id1">
<h3>Cost Function<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><dl class="simple">
<dt><span class="math notranslate nohighlight">\(J(\theta) = \frac{1}{2m} [ \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^{n} \theta_{j}^2 ]\)</span></dt><dd><ul class="simple">
<li><p>Exclude <span class="math notranslate nohighlight">\(\theta_{0}\)</span> for regularization</p></li>
</ul>
</dd>
</dl>
<p><span class="math notranslate nohighlight">\(\min_{\theta} J(\theta)\)</span></p>
</div></blockquote>
</div>
<div class="section" id="id2">
<h3>Gradient descent<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Repeat for each iteration {</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\theta_{0} = \theta_{0} - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) x^{(i)}_{0}\)</span>; (<span class="math notranslate nohighlight">\(j = 0\)</span>)</p>
<p><span class="math notranslate nohighlight">\(\theta_{j} = \theta_{j} - \alpha [\frac{1}{m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) x^{(i)}_{j} +
\frac{\lambda}{m} \theta_{j}]\)</span>; (<span class="math notranslate nohighlight">\(j = 1, ..., n\)</span>)</p>
</div></blockquote>
<p>}</p>
<p><span class="math notranslate nohighlight">\(\theta_{j} = \theta_{j} (1 - \alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) x^{(i)}_{j}\)</span>; (<span class="math notranslate nohighlight">\(j = 1, ..., n\)</span>)</p>
</div></blockquote>
</div>
</div>
<div class="section" id="feature-scaling-label">
<h2><a class="reference internal" href="../_appendix/feature_scaling.html#feature-scaling-label"><span class="std std-ref">Feature Scaling</span></a><a class="headerlink" href="#feature-scaling-label" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="features-and-polynomial-regression">
<h2>Features and Polynomial Regression<a class="headerlink" href="#features-and-polynomial-regression" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>When adding features: <span class="math notranslate nohighlight">\(x^{2}, x^{3}, ...\)</span> and/or <span class="math notranslate nohighlight">\(x_{1}^{2}, x_{1} x_{2}, x_{2}^{2}, ...\)</span>
we can extend linear into complex shapes to better fit our training examples.</p>
<p>Let <span class="math notranslate nohighlight">\(x_{n + 1} = x_{1}^{2}, x_{n + 2} = x_{1} x_{2}, x_{n + 3} = x_{2}^{2}, ...\)</span>
We can continuously call this linear regression.</p>
</div></blockquote>
</div>
<div class="section" id="normal-equation">
<h2>Normal Equation<a class="headerlink" href="#normal-equation" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Method to solve for <span class="math notranslate nohighlight">\(\Theta\)</span> analytically</p>
<blockquote>
<div><ul class="simple">
<li><p>Set <span class="math notranslate nohighlight">\(\frac{\partial }{\partial \theta_{j}} J(\Theta) = 0\)</span> (for every <span class="math notranslate nohighlight">\(j = 0, ..., n\)</span>)</p></li>
<li><p>Solve for <span class="math notranslate nohighlight">\(\theta_{0}, \theta_{1}, \theta_{2}, ..., \theta_{n}\)</span></p></li>
</ul>
</div></blockquote>
<p>Let <span class="math notranslate nohighlight">\(X \in \mathbb {R^{m*(n+1)}}\)</span> and <span class="math notranslate nohighlight">\(y \in \mathbb {R^{m}}\)</span></p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\theta = (X^{T} X)^{-1} X^{T} y \in \mathbb {R^{n + 1}}\)</span></p>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="id3">
<h2>Octave Code<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<div class="highlight-octave notranslate"><div class="highlight"><pre><span></span><span class="n">theta</span> <span class="p">=</span> <span class="nb">pinv</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span>
</pre></div>
</div>
<div class="section" id="regularized-normal-equation">
<h3>Regularized Normal Equation<a class="headerlink" href="#regularized-normal-equation" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(X = {\begin{bmatrix}(x^{(1)})^T\\...\\(x^{(m)})^T\end{bmatrix}} \in \mathbb {R^{m*(n+1)}}\)</span>, <span class="math notranslate nohighlight">\(y = {\begin{bmatrix}y^{(1)}\\...\\y^{(m)}\end{bmatrix}} \in \mathbb {R^{m}}\)</span></p>
<p><span class="math notranslate nohighlight">\(\min_{\theta} J(\theta)\)</span></p>
<p>Let <span class="math notranslate nohighlight">\(I_{\theta} = {\begin{bmatrix}0&amp;0&amp;0&amp;...&amp;0\\0&amp;1&amp;0&amp;...&amp;0\\0&amp;0&amp;1&amp;...&amp;0\\...\\0&amp;0&amp;0&amp;...&amp;1\end{bmatrix}} \in \mathbb {R^{(n+1)*(n+1)}}\)</span></p>
<p><span class="math notranslate nohighlight">\(\theta = (X^{T} X + \lambda I_{\theta})^{-1} X^{T} y \in \mathbb {R^{n + 1}}\)</span></p>
</div></blockquote>
</div>
</div>
<div class="section" id="gradient-descent-vs-normal-equation">
<h2>Gradient Descent vs. Normal Equation<a class="headerlink" href="#gradient-descent-vs-normal-equation" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>For <span class="math notranslate nohighlight">\(m\)</span> training examples, <span class="math notranslate nohighlight">\(n\)</span> features</p>
<p>Gradient Descent:</p>
<ul class="simple">
<li><p>Need to choose <span class="math notranslate nohighlight">\(\alpha\)</span></p></li>
<li><p>Needs many iterations</p></li>
<li><p>Works well even when <span class="math notranslate nohighlight">\(n\)</span> is large (<span class="math notranslate nohighlight">\(n = 10^{6}\)</span>)</p></li>
</ul>
<p>Normal Equation:</p>
<ul class="simple">
<li><p>No need to choose <span class="math notranslate nohighlight">\(\alpha\)</span></p></li>
<li><p>Don’t need to iterate</p></li>
<li><p>Need to compute <span class="math notranslate nohighlight">\((X^{T} X)^{-1} \in \mathbb {R^{n * n}}\)</span>, ~ <span class="math notranslate nohighlight">\(O(n^{3})\)</span></p></li>
<li><p>Slow if <span class="math notranslate nohighlight">\(n\)</span> is very large, OK with <span class="math notranslate nohighlight">\(n = 100; n = 1000\)</span>, move to Gradient Descent when <span class="math notranslate nohighlight">\(n = 10000\)</span></p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="non-invertibility">
<h2>Non-invertibility<a class="headerlink" href="#non-invertibility" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>What if <span class="math notranslate nohighlight">\(X^{T} X\)</span> is non-invertible? (singular/degenerate)</p>
<ul>
<li><p>Redundant features (linearly dependent)</p>
<blockquote>
<div><dl class="simple">
<dt>E.g.</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_{1} =\)</span> size in feet</p></li>
<li><p><span class="math notranslate nohighlight">\(x_{2} =\)</span> size in meter -&gt; <strong>need to delete this feature</strong></p></li>
</ul>
</dd>
</dl>
</div></blockquote>
</li>
<li><p>Too many features (e.g. <span class="math notranslate nohighlight">\(m &lt;= n\)</span>), <span class="math notranslate nohighlight">\(pinv()\)</span> vs. <span class="math notranslate nohighlight">\(inv()\)</span></p>
<blockquote>
<div><ul class="simple">
<li><p>Delete some features, or use regularization</p></li>
<li><p>If <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span>, <span class="math notranslate nohighlight">\((X^{T} X + \lambda I_{\theta})^{-1}\)</span> is invertible</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          
          <h3>Table of Contents</h3>
          <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning.html">Machine Learning</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../supervised_learning.html">Supervised learning</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="logistic_regression.html">Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks.html">Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="support_vector_machines.html">Support Vector Machines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised_learning.html">Unsupervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../special_apps_topics.html">Special Applications/Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advice.html">Advice on Building a ML System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix.html">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorflow.html">TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>

          <div role="search">
            <h3 style="margin-top: 1.5em;">Search</h3>
            <form class="search" action="../search.html" method="get">
                <input type="text" name="q" />
                <input type="submit" value="Go" />
            </form>
          </div>

        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <div role="navigation" aria-label="related navigaton">
            <a href="../supervised_learning.html" title="Supervised learning"
              >previous</a> |
            <a href="logistic_regression.html" title="Logistic Regression"
              >next</a> |
            <a href="../genindex.html" title="General Index"
              >index</a>
          </div>
          <div role="note" aria-label="source link">
              <br/>
              <a href="../_sources/_supervised/linear_regression.rst.txt"
                rel="nofollow">Show Source</a>
          </div>
        </div>

        <div class="right">
          
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Jian Yuan.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.2.1.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>