
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Logistic Regression &#8212; Jian AI Ref 0.1 documentation</title>
    <link rel="stylesheet" href="../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Neural Networks" href="neural_networks.html" />
    <link rel="prev" title="Linear Regression" href="linear_regression.html" /> 
  </head><body>
    <div class="header-wrapper" role="banner">
      <div class="header">
        <div class="headertitle"><a
          href="../index.html">Jian AI Ref 0.1 documentation</a></div>
        <div class="rel" role="navigation" aria-label="related navigation">
          <a href="linear_regression.html" title="Linear Regression"
             accesskey="P">previous</a> |
          <a href="neural_networks.html" title="Neural Networks"
             accesskey="N">next</a> |
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="logistic-regression">
<span id="logistic-regression-label"></span><h1>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><dl class="simple">
<dt>Classification:</dt><dd><ul class="simple">
<li><p>Email: Spam / Not Spam?</p></li>
<li><p>Online Transactions: Fraudulent (Yes / No)?</p></li>
<li><p>Tumor: Malignant / Benign?</p></li>
</ul>
</dd>
<dt>Here, we have:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y \in\)</span> { <span class="math notranslate nohighlight">\(0, 1\)</span> }</p></li>
<li><p><span class="math notranslate nohighlight">\(0\)</span>: “Negative Class” (e.g., benign tumor)</p></li>
<li><p><span class="math notranslate nohighlight">\(1\)</span>: “Positive Class” (e.g., malignant tumor)</p></li>
</ul>
</dd>
<dt>Often, we could have:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y \in\)</span> { <span class="math notranslate nohighlight">\(0, 1, 2, 3, 4, ...\)</span> }</p></li>
</ul>
</dd>
</dl>
</div></blockquote>
<div class="section" id="threshold-classifier">
<h2>Threshold Classifier<a class="headerlink" href="#threshold-classifier" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Threshold classifier output <span class="math notranslate nohighlight">\(h_\theta (x)\)</span> at <span class="math notranslate nohighlight">\(0.5\)</span>:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(h_\theta (x) &gt;= 0.5\)</span>, predict <span class="math notranslate nohighlight">\(y = 1\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(h_\theta (x) &lt; 0.5\)</span>, predict <span class="math notranslate nohighlight">\(y = 0\)</span></p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="hypothesis-representation">
<h2>Hypothesis Representation<a class="headerlink" href="#hypothesis-representation" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>For Linear Regression, we have</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(h_\theta (x) = \theta^{T} x\)</span></p></li>
<li><p>where <span class="math notranslate nohighlight">\(-\infty &lt; h_\theta (x) &lt; \infty\)</span></p></li>
</ul>
</div></blockquote>
<p>Logistic Regression Model</p>
<blockquote>
<div><ul class="simple">
<li><p>Want <span class="math notranslate nohighlight">\(0 &lt;= h_\theta (x) &lt;= 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(h_\theta (x) = g (\theta^{T} x)\)</span></p></li>
</ul>
</div></blockquote>
<p>Let <span class="math notranslate nohighlight">\(z = \theta^{T} x\)</span></p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(g(z) = \frac{1}{1 + e^{-z}}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(h_\theta (x) = \frac{1}{1 + e^{-\theta^{T} x}}\)</span></p></li>
<li><p>This is Sigmoid function (Logistic function)</p></li>
<li><p><span class="math notranslate nohighlight">\(g(z)\)</span> -&gt; <span class="math notranslate nohighlight">\(1\)</span> as <span class="math notranslate nohighlight">\(z\)</span> -&gt; <span class="math notranslate nohighlight">\(\infty\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(g(z) = 0.5\)</span> as <span class="math notranslate nohighlight">\(z = 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(g(z)\)</span> -&gt; <span class="math notranslate nohighlight">\(0\)</span> as <span class="math notranslate nohighlight">\(z\)</span> -&gt; <span class="math notranslate nohighlight">\(-\infty\)</span></p></li>
</ul>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="interpretation-of-hypothesis-output">
<h2>Interpretation of Hypothesis Output<a class="headerlink" href="#interpretation-of-hypothesis-output" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(h_\theta (x)\)</span> = estimated probability that <span class="math notranslate nohighlight">\(y = 1\)</span> on input <span class="math notranslate nohighlight">\(x\)</span></p>
<p>Example:</p>
<blockquote>
<div><ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(x = {\begin{bmatrix}x_{0}\\x_{1}\end{bmatrix}} = {\begin{bmatrix}1\\tumorSize\end{bmatrix}}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(h_\theta (x) = 0.7\)</span> interpreted as <span class="math notranslate nohighlight">\(y = 1\)</span></p></li>
<li><p>Tell patient that 70% chance of tumor being malignant</p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y \in\)</span> { <span class="math notranslate nohighlight">\(0, 1\)</span> }</p></li>
<li><p><span class="math notranslate nohighlight">\(h_\theta (x) = P(y = 1|x; \theta)\)</span> is the probability that <span class="math notranslate nohighlight">\(y = 1\)</span>, given <span class="math notranslate nohighlight">\(x\)</span>, parameterized by <span class="math notranslate nohighlight">\(\theta\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(y = 0|x; \theta) + P(y = 1|x; \theta) = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(y = 0|x; \theta) = 1 - P(y = 1|x; \theta)\)</span></p></li>
</ul>
<p>Or simply</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(y = 0) + P(y = 1) = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(y = 0) = 1 - P(y = 1)\)</span></p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="decision-boundary">
<h2>Decision Boundary<a class="headerlink" href="#decision-boundary" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Logistic Regression</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(h_\theta (x) = g (\theta^{T} x)\)</span> and <span class="math notranslate nohighlight">\(z = \theta^{T} x\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(g(z) = \frac{1}{1 + e^{-z}}\)</span></p></li>
</ul>
</div></blockquote>
<p>Plot <span class="math notranslate nohighlight">\(g(z)\)</span> vs. <span class="math notranslate nohighlight">\(z\)</span> curve, we get:</p>
<blockquote>
<div><ul class="simple">
<li><p>predict <span class="math notranslate nohighlight">\(y = 1\)</span> if <span class="math notranslate nohighlight">\(h_\theta (x) &gt;= 0.5\)</span> therefore <span class="math notranslate nohighlight">\(z = \theta^{T} x &gt;= 0\)</span></p></li>
<li><p>predict <span class="math notranslate nohighlight">\(y = 0\)</span> if <span class="math notranslate nohighlight">\(h_\theta (x) &lt; 0.5\)</span> therefore <span class="math notranslate nohighlight">\(z = \theta^{T} x &lt; 0\)</span></p></li>
</ul>
</div></blockquote>
<p>Solve for <span class="math notranslate nohighlight">\(\theta^{T} x &gt;= 0\)</span>, we can get linear or non-linear decision boundaries.</p>
</div></blockquote>
</div>
<div class="section" id="cost-function">
<h2>Cost Function<a class="headerlink" href="#cost-function" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Training set, <span class="math notranslate nohighlight">\(m\)</span> examples: <span class="math notranslate nohighlight">\({ (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), ..., (x^{(m)}, y^{(m)}) }\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x = {\begin{bmatrix}x_{0}\\x_{1}\\...\\x_{n}\end{bmatrix}} \in \mathbb {R^{n+1}}\)</span>, <span class="math notranslate nohighlight">\(x_{0} = 1\)</span>, <span class="math notranslate nohighlight">\(y \in\)</span> { <span class="math notranslate nohighlight">\(0, 1\)</span> }</p></li>
<li><p>For <span class="math notranslate nohighlight">\(h_\theta (x) = \frac{1}{1 + e^{-\theta^{T} x}}\)</span>, how to choose parameters <span class="math notranslate nohighlight">\(\theta\)</span>?</p></li>
</ul>
<p>Logistic Regression</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(J(\theta) = \frac{1}{m} \sum_{i=1}^{m} Cost(h_\theta (x^{(i)}), y^{(i)})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Cost(h_\theta (x^{(i)}), y^{(i)}) = \frac{1}{2} (h_\theta (x^{(i)}) - y^{(i)})^2\)</span></p></li>
</ul>
</div></blockquote>
<p>Or simply</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Cost(h_\theta (x), y) = \frac{1}{2} (h_\theta (x) - y)^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(h_\theta (x) = \frac{1}{1 + e^{-\theta^{T} x}}\)</span></p></li>
</ul>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="logistic-regression-cost-function">
<h2>Logistic Regression Cost Function<a class="headerlink" href="#logistic-regression-cost-function" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(Cost(h_\theta (x), y) = {\begin{cases}- \log(h_\theta (x))&amp;y = 1\\- \log(1 - h_\theta (x))&amp;y = 0\end{cases}}\)</span></p>
<p>Plot <span class="math notranslate nohighlight">\(Cost(h_\theta (x), y = 1)\)</span> vs. <span class="math notranslate nohighlight">\(h_\theta (x)\)</span> curve</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Cost = 0\)</span>, if <span class="math notranslate nohighlight">\(h_\theta (x) = 1\)</span></p></li>
<li><p>But as <span class="math notranslate nohighlight">\(h_\theta (x)\)</span> -&gt; <span class="math notranslate nohighlight">\(0\)</span>, <span class="math notranslate nohighlight">\(Cost\)</span> -&gt; <span class="math notranslate nohighlight">\(\infty\)</span></p></li>
<li><p>Captures intuition that if <span class="math notranslate nohighlight">\(h_\theta (x) = 0\)</span>, (predict <span class="math notranslate nohighlight">\(h_\theta (x) = P(y = 1|x; \theta) = 0\)</span>), but <span class="math notranslate nohighlight">\(y = 1\)</span>, we will penalize the learning algorithm by a very large cost.</p></li>
</ul>
</div></blockquote>
<p>Plot <span class="math notranslate nohighlight">\(Cost(h_\theta (x), y = 0)\)</span> vs. <span class="math notranslate nohighlight">\(h_\theta (x)\)</span> curve</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Cost = 0\)</span>, if <span class="math notranslate nohighlight">\(h_\theta (x) = 0\)</span></p></li>
<li><p>But as <span class="math notranslate nohighlight">\(h_\theta (x)\)</span> -&gt; <span class="math notranslate nohighlight">\(1\)</span>, <span class="math notranslate nohighlight">\(Cost\)</span> -&gt; <span class="math notranslate nohighlight">\(\infty\)</span></p></li>
<li><p>Captures intuition that if <span class="math notranslate nohighlight">\(h_\theta (x) = 1\)</span>, (predict <span class="math notranslate nohighlight">\(h_\theta (x) = P(y = 0|x; \theta) = 1\)</span>), but <span class="math notranslate nohighlight">\(y = 0\)</span>, we will penalize the learning algorithm by a very large cost.</p></li>
</ul>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="simplified-cost-function-and-gradient-descent">
<h2>Simplified Cost Function and Gradient Descent<a class="headerlink" href="#simplified-cost-function-and-gradient-descent" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Cost Function</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(J(\theta) = \frac{1}{m} \sum_{i=1}^{m} Cost(h_\theta (x^{(i)}), y^{(i)})\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Cost(h_\theta (x), y) = {\begin{cases}- \log(h_\theta (x))&amp;y = 1\\- \log(1 - h_\theta (x))&amp;y = 0\end{cases}}\)</span></p></li>
</ul>
</div></blockquote>
<p>Therefore</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Cost(h_\theta (x), y) = -y \log(h_\theta (x)) -(1 - y) \log(1 - h_\theta (x))\)</span>, <span class="math notranslate nohighlight">\(y \in\)</span> { <span class="math notranslate nohighlight">\(0, 1\)</span> }</p></li>
<li><p><span class="math notranslate nohighlight">\(J(\theta) = - \frac{1}{m} [ \sum_{i=1}^{m} y^{(i)} \log(h_\theta (x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta (x^{(i)})) ]\)</span></p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p>To fit parameters <span class="math notranslate nohighlight">\(\theta\)</span>: minimize <span class="math notranslate nohighlight">\(J(\theta)\)</span></p></li>
<li><p>To make a prediction given new: <span class="math notranslate nohighlight">\(x\)</span>, compute output <span class="math notranslate nohighlight">\(h_\theta (x) = \frac{1}{1 + e^{-\theta^{T} x}}\)</span></p></li>
<li><p>Recall <span class="math notranslate nohighlight">\(h_\theta (x) = P(y = 1|x; \theta)\)</span></p></li>
</ul>
<p>Gradient Descent</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(J(\theta) = - \frac{1}{m} [ \sum_{i=1}^{m} y^{(i)} \log(h_\theta (x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta (x^{(i)})) ]\)</span></p>
<p><span class="math notranslate nohighlight">\(\min_{\theta} J(\theta)\)</span></p>
<p>Repeat for each iteration {</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\theta_{j} = \theta_{j} - \alpha \frac{\partial }{\partial \theta_{j}} J(\theta) = \theta_{j} - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) x^{(i)}_{j}\)</span> (<span class="math notranslate nohighlight">\(j = 0, ..., n\)</span>)</p>
</div></blockquote>
<p>}</p>
<p><span class="math notranslate nohighlight">\(\alpha\)</span> = <a class="reference internal" href="../_appendix/learning_rate.html#learning-rate-label"><span class="std std-ref">Learning Rate</span></a></p>
<p>Algorithm looks identical to linear regression!</p>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="regularized-logistic-regression">
<h2>Regularized Logistic Regression<a class="headerlink" href="#regularized-logistic-regression" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Cost Function<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(J(\theta) = - \frac{1}{m} [ \sum_{i=1}^{m} y^{(i)} \log(h_\theta (x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta (x^{(i)})) ] +
\frac{\lambda}{2m} \sum_{j=1}^{n} \theta_{j}^2\)</span></p>
<blockquote>
<div><ul class="simple">
<li><p>Exclude <span class="math notranslate nohighlight">\(\theta_{0}\)</span> for regularization</p></li>
</ul>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="gradient-descent">
<h3>Gradient descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Repeat for each iteration {</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\theta_{0} = \theta_{0} - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) x^{(i)}_{0}\)</span>; (<span class="math notranslate nohighlight">\(j = 0\)</span>)</p>
<p><span class="math notranslate nohighlight">\(\theta_{j} = \theta_{j} - \alpha [\frac{1}{m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) x^{(i)}_{j} +
\frac{\lambda}{m} \theta_{j}]\)</span>; (<span class="math notranslate nohighlight">\(j = 1, ..., n\)</span>)</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>TODO: mid Week3_2</p>
</div>
</div>
<div class="section" id="advanced-optimization">
<h2>Advanced Optimization<a class="headerlink" href="#advanced-optimization" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl>
<dt>Optimization Algorithm</dt><dd><ul>
<li><p>Cost function <span class="math notranslate nohighlight">\(J(\theta)\)</span>. Want to minimize <span class="math notranslate nohighlight">\(J(\theta)\)</span></p></li>
<li><dl class="simple">
<dt>Given <span class="math notranslate nohighlight">\(\theta\)</span>, we have code that can compute</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(J(\theta)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\frac{\partial }{\partial \theta_{j}} J(\theta)\)</span> (for every <span class="math notranslate nohighlight">\(j = 0, ..., n\)</span>)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt>Gradient Descent:</dt><dd><p>Repeat for each iteration {</p>
<blockquote>
<div><p><span class="math notranslate nohighlight">\(\theta_{j} = \theta_{j} - \alpha \frac{\partial }{\partial \theta_{j}} J(\theta)\)</span></p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Optimization Algorithms:</dt><dd><ul class="simple">
<li><p>Gradient descent</p></li>
<li><p>Conjugate gradient</p></li>
<li><p>BFGS</p></li>
<li><p>L-BFGS</p></li>
</ul>
</dd>
<dt>Advantages:</dt><dd><ul class="simple">
<li><p>No need to manually pick <span class="math notranslate nohighlight">\(\alpha\)</span></p></li>
<li><p>Often faster than gradient descent</p></li>
</ul>
</dd>
<dt>Disadvantages:</dt><dd><ul class="simple">
<li><p>More complex</p></li>
</ul>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="multi-class-classification-one-vs-all">
<h2>Multi-class Classification: One-vs-All<a class="headerlink" href="#multi-class-classification-one-vs-all" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl class="simple">
<dt>Multiclass Classification:</dt><dd><ul class="simple">
<li><p>Email foldering/tagging: Work, Friends, Family, Hobby (<span class="math notranslate nohighlight">\(y \in\)</span> { <span class="math notranslate nohighlight">\(1, 2, 3, 4\)</span> })</p></li>
<li><p>Medical diagrams: Not ill, Cold, Flu (<span class="math notranslate nohighlight">\(y \in\)</span> { <span class="math notranslate nohighlight">\(1, 2, 3\)</span> })</p></li>
<li><p>Weather: Sunny, Cloudy, Rain, Snow (<span class="math notranslate nohighlight">\(y \in\)</span> { <span class="math notranslate nohighlight">\(1, 2, 3, 4\)</span> })</p></li>
</ul>
</dd>
<dt>One-vs-all (one-vs-rest):</dt><dd><ul class="simple">
<li><p>Class 1:</p></li>
<li><p>Class 2:</p></li>
<li><p>Class 3:</p></li>
<li><p><span class="math notranslate nohighlight">\(h_\theta^{(i)} (x) = P(y = i|x; \theta)\)</span> (<span class="math notranslate nohighlight">\(i \in\)</span> { <span class="math notranslate nohighlight">\(1, 2, 3\)</span> })</p></li>
</ul>
</dd>
<dt>One-vs-All:</dt><dd><ul class="simple">
<li><p>Train a logistic regression classifier <span class="math notranslate nohighlight">\(h_\theta^{(i)} (x)\)</span> for each class <span class="math notranslate nohighlight">\(i\)</span> to predict the probability that <span class="math notranslate nohighlight">\(y = i\)</span></p></li>
<li><p>On a new input <span class="math notranslate nohighlight">\(x\)</span>, to make a prediction, pick the class <span class="math notranslate nohighlight">\(i\)</span> that maximizes <span class="math notranslate nohighlight">\(h_\theta^{(i)} (x)\)</span></p></li>
</ul>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="regularization-label">
<h2><a class="reference internal" href="../_appendix/regularization.html#regularization-label"><span class="std std-ref">Regularization</span></a><a class="headerlink" href="#regularization-label" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y_{n+1}={\begin{cases}2y_{n}&amp;0\leq y_{n}&lt;{\tfrac {1}{2}}\\2y_{n}-1&amp;{\tfrac {1}{2}}\leq y_{n}&lt;1,\end{cases}}\)</span></p></li>
</ul>
</div></blockquote>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          
          <h3>Table of Contents</h3>
          <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning.html">Machine Learning</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../supervised_learning.html">Supervised learning</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="linear_regression.html">Linear Regression</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks.html">Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="support_vector_machines.html">Support Vector Machines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised_learning.html">Unsupervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../special_apps_topics.html">Special Applications/Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advice.html">Advice on Building a ML System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix.html">Appendix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensorflow.html">TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>

          <div role="search">
            <h3 style="margin-top: 1.5em;">Search</h3>
            <form class="search" action="../search.html" method="get">
                <input type="text" name="q" />
                <input type="submit" value="Go" />
            </form>
          </div>

        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <div role="navigation" aria-label="related navigaton">
            <a href="linear_regression.html" title="Linear Regression"
              >previous</a> |
            <a href="neural_networks.html" title="Neural Networks"
              >next</a> |
            <a href="../genindex.html" title="General Index"
              >index</a>
          </div>
          <div role="note" aria-label="source link">
              <br/>
              <a href="../_sources/_supervised/logistic_regression.rst.txt"
                rel="nofollow">Show Source</a>
          </div>
        </div>

        <div class="right">
          
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Jian Yuan.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.2.1.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>